from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from starlette.websockets import WebSocketDisconnect
import cv2
import numpy as np
import base64
import os
import uuid
from pathlib import Path
from fastapi import UploadFile, File, BackgroundTasks
from typing import Optional
import traceback
from datn_ai import FaceEmotionTracker
import datn_ai  # Import module ƒë·ªÉ d√πng process_video function

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Kh·ªüi t·∫°o model
tracker = FaceEmotionTracker()

# Setup video directories
TEMP_DIR = Path("./temp_videos")
OUTPUT_DIR = Path("./output_videos")
TEMP_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# L∆∞u tr·∫°ng th√°i c√°c job ƒëang x·ª≠ l√Ω
video_jobs = {}

@app.websocket("/ws/process")
async def ai_websocket(ws: WebSocket):
    await ws.accept()
    print("‚úÖ AI WebSocket connected!")
    
    is_processing = False  
    frame_skip_count = 0  
    
    try:
        while True:
            # Nh·∫≠n frame
            data = await ws.receive_bytes()
            
            # SKIP FRAME n·∫øu ƒëang x·ª≠ l√Ω
            if is_processing:
                frame_skip_count += 1
                continue
            
            # LOG C·∫¢NH B√ÅO n·∫øu skip qu√° nhi·ªÅu frame
            if frame_skip_count > 5:
                print(f" B·ªè qua {frame_skip_count} frames do x·ª≠ l√Ω ch·∫≠m")
            frame_skip_count = 0
                
            is_processing = True
            
            np_arr = np.frombuffer(data, np.uint8)
            frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            
            if frame is None:
                is_processing = False
                continue

            # X·ª≠ l√Ω frame
            result = tracker.process_frame(frame)
            
            # GI·∫¢M CH·∫§T L∆Ø·ª¢NG JPEG khi encode
            _, buffer = cv2.imencode('.jpg', result['frame'], [
                cv2.IMWRITE_JPEG_QUALITY, 70  # Gi·∫£m t·ª´ 85 xu·ªëng 70
            ])
            frame_base64 = base64.b64encode(buffer).decode('utf-8')
            
            await ws.send_json({
                'frame': frame_base64,
                'fps': result['fps'],
                'tracks': result['tracks']
            })
            
            is_processing = False
    
    except WebSocketDisconnect:
        print(" Client kh√¥ng c√≤n k·∫øt n·ªëi, ƒë√≥ng WebSocket")
    except Exception as e:
        print(f"AI Websocket g·∫∑p l·ªói: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # Ch·ªâ close n·∫øu WebSocket ch∆∞a ƒë√≥ng
        try:
            await ws.close()
            print(" AI WebSocket ƒë√≥ng")
        except:
            pass

@app.get("/health")
async def health_check():
    """API health ki·ªÉm tra endpoint."""
    return {"status": "ok", "service": "AI Emotion Detection"}

# ====== VIDEO PROCESSING ENDPOINTS ======

def process_video_task(job_id: str, input_path: str, output_path: str, skip_frames: int):
    """Background task x·ª≠ l√Ω video"""
    try:
        # C·∫≠p nh·∫≠t status
        video_jobs[job_id]["status"] = "processing"
        video_jobs[job_id]["progress"] = 0
        
        print(f"üé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video job {job_id}")
        
        # G·ªçi h√†m process_video t·ª´ datn_ai v·ªõi ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng
        result = datn_ai.FaceEmotionTracker.process_video(
            input_video_path=input_path,
            output_video_path=output_path,
            skip_frames=skip_frames,
            show_preview=False
        )
        
        # C·∫≠p nh·∫≠t k·∫øt qu·∫£ v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß
        video_jobs[job_id].update({
            "status": "completed",
            "progress": 100,
            "result": {
                "total_visitor": result['total_visitor'],
                "emotion_ratios": result['emotion_ratios'],
                "total_frames": result['total_frames'],
                "processed_frames": result['processed_frames'],
                "fps": result['fps'],
                "resolution": result['resolution']
            }
        })
        
        print(f"‚úÖ Job {job_id} ho√†n th√†nh!")
        print(f"   - Total visitors: {result['total_visitor']}")
        print(f"   - Processed frames: {result['processed_frames']}/{result['total_frames']}")
        
    except Exception as e:
        video_jobs[job_id].update({
            "status": "failed",
            "error": str(e),
            "traceback": traceback.format_exc()
        })
        print(f"‚ùå Job {job_id} th·∫•t b·∫°i: {e}")
        traceback.print_exc()

@app.post("/api/video/upload-and-process")
async def upload_and_process_video(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    skip_frames: int = 1
):
    """Upload video v√† x·ª≠ l√Ω v·ªõi face tracking + emotion detection"""
    
    # Validate file type
    if not file.filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
        raise HTTPException(status_code=400, detail="Ch·ªâ h·ªó tr·ª£ video format: mp4, avi, mov, mkv")
    
    # T·∫°o job ID
    job_id = str(uuid.uuid4())
    
    # T·∫°o ƒë∆∞·ªùng d·∫´n file
    safe_filename = "".join(c for c in file.filename if c.isalnum() or c in "._- ")
    input_path = TEMP_DIR / f"{job_id}_{safe_filename}"
    output_path = OUTPUT_DIR / f"{job_id}_processed.mp4"
    
    # L∆∞u file upload
    try:
        with open(input_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Kh√¥ng th·ªÉ l∆∞u file: {str(e)}")
    
    # T·∫°o job info
    video_jobs[job_id] = {
        "status": "queued",
        "progress": 0,
        "filename": file.filename,
        "input_path": str(input_path),
        "output_path": str(output_path),
        "error": None
    }
    
    # Ch·∫°y background task
    background_tasks.add_task(
        process_video_task,
        job_id,
        str(input_path),
        str(output_path),
        skip_frames
    )
    
    print(f"üì§ Job {job_id} ƒë√£ ƒë∆∞·ª£c t·∫°o cho file: {file.filename}")
    
    return {
        "job_id": job_id,
        "message": "Video ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω",
        "filename": file.filename,
        "status_url": f"/api/video/status/{job_id}"
    }

@app.get("/api/video/status/{job_id}")
async def get_video_status(job_id: str):
    """Ki·ªÉm tra tr·∫°ng th√°i x·ª≠ l√Ω video"""
    
    if job_id not in video_jobs:
        raise HTTPException(status_code=404, detail="Job kh√¥ng t·ªìn t·∫°i")
    
    return video_jobs[job_id]

@app.get("/api/video/download/{job_id}")
async def download_processed_video(job_id: str):
    """Download video ƒë√£ x·ª≠ l√Ω"""
    
    if job_id not in video_jobs:
        raise HTTPException(status_code=404, detail="Job kh√¥ng t·ªìn t·∫°i")
    
    job = video_jobs[job_id]
    
    if job["status"] != "completed":
        raise HTTPException(
            status_code=400, 
            detail=f"Video ch∆∞a x·ª≠ l√Ω xong. Status: {job['status']}, Progress: {job.get('progress', 0)}%"
        )
    
    output_path = job["output_path"]
    
    if not os.path.exists(output_path):
        raise HTTPException(status_code=404, detail="File output kh√¥ng t·ªìn t·∫°i")
    
    return FileResponse(
        output_path,
        media_type="video/mp4",
        filename=f"processed_{job['filename']}"
    )

if __name__ == "__main__":
    import uvicorn
    print("üöÄ Starting AI Server on port 8001...")
    uvicorn.run(app, host="0.0.0.0", port=8001)